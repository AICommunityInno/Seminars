{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Community @ Семинар № 2\n",
    "## TF-IDF\n",
    "\n",
    "### Введение\n",
    "TF-IDF - технология NLP, Information Retrieval и Data Mining для анализа классифицированных датасетов, показывающая насколько слово важно для класса (документа)\n",
    "\n",
    "TF-IDF - Term Frequency - Inverted Document Frequency\n",
    "\n",
    "**Term Frequency** - $tf(t,d)$ - насколько часто терм $t$ встречается в документе $d$  \n",
    "**Inverted Document Frequency** - $idf(t,D)$ - насколько терм $t$ значим для документа в датасете $D$. Пример: если в новости есть слово \"Путин\", то новость скорее всего про политику, а если там есть слово \"он\", то категория может быть любая.\n",
    "\n",
    "\n",
    "Варианты вычисления $tf(t,d)$:\n",
    "1. $tf(t,d)$ = 1 или 0 (есть терм в документе или нет)\n",
    "1. $tf(t,d) = с_{t,d}$ (количество упоминаний терма в документе)\n",
    "1. $tf(t,d) = \\frac{с_{t,d}}{\\sum_{t'}с_{t,d}}$ (частота упоминания терма в документе)\n",
    "1. $tf(t,d) = 1 + \\log с_{t,d}$ (лог-нормализация)\n",
    "\n",
    "Варианты вычисления $idf(t,D)$:\n",
    "1. $idf(t,D) = 1$ (все слова одинаково репрезентативны)\n",
    "2. $idf(t,D) = -\\log \\frac{n_t}{N}$, $n_t$ - количество документов, в которых встретился терм $t$\n",
    "2. $idf(t,D) = \\log (1+\\frac{N}{n_t})$, $n_t$ - то же самое, но сглаженное (никогда не 0) \n",
    "\n",
    "Теперь мы можем определить \"ценность\" терма для документа как \n",
    "\n",
    "$$tfidf(t,d,D) = tf(t,d)\\cdot idf(t,D)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример для задачи классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import nltk\n",
    "stemmer = nltk.SnowballStemmer('english')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import reuters\n",
    "sw = stopwords.words('english')\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "regexp = re.compile('[a-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats_joined = dict()\n",
    "for f_id in tqdm(reuters.fileids()):\n",
    "    cat = reuters.categories(f_id)[0]      \n",
    "    words = [stemmer.stem(word.lower()) for word in reuters.words(f_id) if len(word) > 2 and regexp.match(word)]\n",
    "    if cat in cats_joined:\n",
    "        cats_joined[cat] += ' '.join(words)\n",
    "    else:\n",
    "        cats_joined[cat] = ' '.join(words)\n",
    "cats_list = [cats_joined[key] for key in sorted(cats_joined)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=3,\n",
    "                                   max_features=2000,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(cats_joined.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут лежат слова, индексы соответствуют столбцам матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_words = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут лежат категории, индексы соответствуют столбцам матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted(cats_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А это сама матрица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим слова, соответствующие категории \"какао\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "print(categories[i])\n",
    "np.array(best_words)[np.argsort(tfidf[i])][-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent semantic analysis (Латентно-семантический анализ)\n",
    "Задача: определить, похожи ли два терма или два документа друг на друга  \n",
    "Идея: Похожие документы характеризуются похожими словами \n",
    "\n",
    "Обозначим матрицу TF-IDF как $X$\n",
    "Определим похожесть термов $i$ и $j$ как $c_i^Tc_j$, где $c_i$ - столбец матрицы $X$, соответствующий терму $i$.\n",
    "Тогда $X^TX$ будет содержать все возможные пары похожих слов\n",
    "\n",
    "Известно, что для любой матрицы существует SVD-разложение:  \n",
    "$$X = U \\Sigma V^T$$\n",
    "Где $\\Sigma$ - диагональная матрица, $U$,$V$ - ортогональные матрицы ($UU^T=U^TU=I$).\n",
    "Тогда $$X^TX = V \\Sigma^T U^T U \\Sigma V^T = V \\Sigma^T \\Sigma V^T$$\n",
    "Отсюда $X = \\Sigma V^T$\n",
    "\n",
    "Всё ещё вычислительно трудно.\n",
    "\n",
    "Но в $\\Sigma$ может быть определённое количество близких к нулю значений, они почти не влияют на матрицу. Поэтому можно приблизить $V \\Sigma^T \\Sigma V^T$ как $V_k \\Sigma_k^T \\Sigma_k V_k^T$, где индекс $k$ означает, что мы берём строки/столбцы, соответствующие $k$ наибольшим значениям матрицы $\\Sigma$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=2)\n",
    "ans = tsvd.fit_transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.scatter(ans[:,0],ans[:,1])\n",
    "for i, txt in enumerate(categories):\n",
    "    plt.annotate(txt, (ans[i,0],ans[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
