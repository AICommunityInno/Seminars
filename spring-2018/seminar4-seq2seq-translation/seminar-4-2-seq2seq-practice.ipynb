{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Community @ Семинар № 4, весна 2018\n",
    "## Машинный перевод и Внимание: Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from os.path import join\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "hidden_size = 256\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import prepareData, variablesFromPair, timeSince, evaluate, showPlot, evaluateAndShowAttention\n",
    "from util import SOS_token, EOS_token, MAX_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 159204 sentence pairs\n",
      "Trimmed to 8863 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "deu 4543\n",
      "eng 3003\n",
      "Reading lines...\n",
      "Read 115245 sentence pairs\n",
      "Trimmed to 7400 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "spa 3908\n",
      "eng 2788\n"
     ]
    }
   ],
   "source": [
    "input_lang_german, output_lang_german, pairs_german = prepareData('eng', 'deu', True)\n",
    "input_lang_spanish, output_lang_spanish, pairs_spanish = prepareData('eng', 'spa', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодировщик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Декодировщик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Внимательный декодировщик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/attention_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, input_lang, output_lang, pairs, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs), input_lang, output_lang)\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(input_lang_german.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang_german.n_words, dropout_p=0.1)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, input_lang_german, output_lang_german, pairs_german, 20000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, input_lang, output_lang, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1, input_lang_german, output_lang_german, pairs_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, _ = evaluate(encoder1, attn_decoder1, ' wasser ', input_lang_german, output_lang_german)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение и загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(encoder1.state_dict(), \"./models/encoder\")\n",
    "torch.save(attn_decoder1.state_dict(), \"./models/decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder2 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "encoder2.load_state_dict(torch.load(\"./models/encoder\"))\n",
    "attn_decoder2.load_state_dict(torch.load(\"./models/decoder\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обученные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_models(encoder_name, decoder_name, input_lang, output_lang, models_path='./models/'):\n",
    "    encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "    decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "    encoder.load_state_dict(torch.load(join(models_path, encoder_name), map_location=lambda storage, loc: storage))\n",
    "    decoder.load_state_dict(torch.load(join(models_path, decoder_name), map_location=lambda storage, loc: storage))\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Немецкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/german_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_german, decoder_german = load_models(\"encoder_german\", \"decoder_german\", input_lang_german, output_lang_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> sie fotografiert gerne .\n",
      "= she s fond of taking pictures .\n",
      "< she s fond of she . <EOS>\n",
      "\n",
      "> sie isst fur zwei .\n",
      "= she s eating for two .\n",
      "< she s eating for two . <EOS>\n",
      "\n",
      "> ich bin heute niedergeschlagen .\n",
      "= i m in low spirits today .\n",
      "< i m in low today spirits today . <EOS>\n",
      "\n",
      "> ihr verschwendet blo eure zeit .\n",
      "= you re just wasting your time .\n",
      "< you re just wasting your time . <EOS>\n",
      "\n",
      "> ich fahre erst morgen .\n",
      "= i m not leaving until tomorrow .\n",
      "< i m not leaving until tomorrow . <EOS>\n",
      "\n",
      "> wir sind partner .\n",
      "= we re partners .\n",
      "< we re partners . <EOS>\n",
      "\n",
      "> ich gehe schnell duschen .\n",
      "= i m going to take a quick shower .\n",
      "< i m going to take a shower . <EOS>\n",
      "\n",
      "> es tut mir sehr leid das zu horen .\n",
      "= i am really sorry to hear that .\n",
      "< i am really sorry to hear that . . <EOS>\n",
      "\n",
      "> ich mache mir gro e sorgen um tom .\n",
      "= i m very worried about tom .\n",
      "< i m very worried about tom . <EOS>\n",
      "\n",
      "> das war sicher nicht mit absicht .\n",
      "= i m sure that wasn t intentional .\n",
      "< i m sure that t t to . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder_german, decoder_german, input_lang_german, output_lang_german, pairs_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Испанский"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/spanish_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_spanish, decoder_spanish = load_models(\"encoder_spanish\", \"decoder_spanish\", input_lang_spanish, output_lang_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> no me gusta su cara .\n",
      "= i m not fond of her face .\n",
      "< i m not fond of her face . <EOS>\n",
      "\n",
      "> soy bueno esquiando .\n",
      "= i m good at skiing .\n",
      "< i m good at skiing . <EOS>\n",
      "\n",
      "> voy de camino a la estacion .\n",
      "= i m on my way to the station .\n",
      "< i m on my way to way . <EOS>\n",
      "\n",
      "> estamos en una biblioteca .\n",
      "= we are in a library .\n",
      "< we re a bad library . <EOS>\n",
      "\n",
      "> somos los padres de tom .\n",
      "= we re tom s parents .\n",
      "< we re tom s parents . <EOS>\n",
      "\n",
      "> me estoy preguntando si la amo .\n",
      "= i m wondering if i love her .\n",
      "< i m wondering if i love her . <EOS>\n",
      "\n",
      "> aqui todos somos canadienses .\n",
      "= we re all canadians here .\n",
      "< we re all canadians here . <EOS>\n",
      "\n",
      "> yo no estoy acostumbrado a trabajar duro .\n",
      "= i am not used to hard work .\n",
      "< i am not accustomed to hard at work . <EOS>\n",
      "\n",
      "> le envio una postal .\n",
      "= she sent him a postcard .\n",
      "< she sent him a postcard . <EOS>\n",
      "\n",
      "> el es mas brillante que ellos .\n",
      "= he s brighter than they are .\n",
      "< he s brighter than they are . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder_spanish, decoder_spanish, input_lang_spanish, output_lang_spanish, pairs_spanish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на внимание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = ich warte hier\n",
      "output = i m waiting for my . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEJCAYAAACJwawLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEVFzSeQRETWXRB4RUXP/H70eFRBNlYBKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b955588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"ich warte hier\", encoder_german, decoder_german, input_lang_german, output_lang_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источники:\n",
    "1. [Pytorch seq2seq tutorial](http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "2. [Про Attention](https://arxiv.org/abs/1406.6247)\n",
    "3. [Еще про Attention](https://arxiv.org/abs/1508.04025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
