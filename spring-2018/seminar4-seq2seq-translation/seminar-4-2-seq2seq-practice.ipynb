{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Community @ Семинар № 4, весна 2018\n",
    "## Машинный перевод и Внимание: Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from os.path import join\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "hidden_size = 256\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import prepareData, variablesFromPair, timeSince, evaluate, showPlot, evaluateAndShowAttention\n",
    "from util import SOS_token, EOS_token, MAX_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 159204 sentence pairs\n",
      "Trimmed to 8863 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "deu 4543\n",
      "eng 3003\n",
      "Reading lines...\n",
      "Read 115245 sentence pairs\n",
      "Trimmed to 7400 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "spa 3908\n",
      "eng 2788\n"
     ]
    }
   ],
   "source": [
    "input_lang_german, output_lang_german, pairs_german = prepareData('eng', 'deu', True)\n",
    "input_lang_spanish, output_lang_spanish, pairs_spanish = prepareData('eng', 'spa', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодировщик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Декодировщик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Внимательный декодировщик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/attention_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, input_lang, output_lang, pairs, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs), input_lang, output_lang)\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 11s (- 38m 54s) (100 0%) 4.6258\n",
      "0m 22s (- 36m 24s) (200 1%) 3.7308\n",
      "0m 32s (- 35m 43s) (300 1%) 3.7086\n",
      "0m 44s (- 36m 11s) (400 2%) 3.7251\n",
      "0m 55s (- 35m 53s) (500 2%) 3.4275\n",
      "1m 6s (- 35m 52s) (600 3%) 3.5124\n",
      "1m 18s (- 35m 51s) (700 3%) 3.4807\n",
      "1m 29s (- 35m 51s) (800 4%) 3.3684\n",
      "1m 41s (- 35m 57s) (900 4%) 3.5731\n",
      "1m 53s (- 35m 53s) (1000 5%) 3.3962\n",
      "2m 4s (- 35m 41s) (1100 5%) 3.2443\n",
      "2m 16s (- 35m 35s) (1200 6%) 3.3506\n",
      "2m 28s (- 35m 34s) (1300 6%) 3.3747\n",
      "2m 40s (- 35m 36s) (1400 7%) 3.1993\n",
      "2m 51s (- 35m 15s) (1500 7%) 3.1254\n",
      "3m 3s (- 35m 5s) (1600 8%) 3.1423\n",
      "3m 15s (- 34m 59s) (1700 8%) 3.1915\n",
      "3m 26s (- 34m 43s) (1800 9%) 3.2128\n",
      "3m 37s (- 34m 31s) (1900 9%) 3.2244\n",
      "3m 48s (- 34m 17s) (2000 10%) 3.1062\n",
      "4m 0s (- 34m 7s) (2100 10%) 3.0347\n",
      "4m 11s (- 33m 52s) (2200 11%) 2.9779\n",
      "4m 22s (- 33m 40s) (2300 11%) 3.2120\n",
      "4m 33s (- 33m 27s) (2400 12%) 3.1998\n",
      "4m 44s (- 33m 13s) (2500 12%) 3.0732\n",
      "4m 57s (- 33m 10s) (2600 13%) 3.1270\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1715c622466c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang_german\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang_german\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_german\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c45c599ce7cd>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, input_lang, output_lang, pairs, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_variable, target_variable, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-228dc0e14dc5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(input_lang_german.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang_german.n_words, dropout_p=0.1)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, input_lang_german, output_lang_german, pairs_german, 20000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, input_lang, output_lang, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ich denke an etwas anderes .\n",
      "= i m thinking about something else .\n",
      "< i am very very . <EOS>\n",
      "\n",
      "> wir sind in einer schwierigen situation .\n",
      "= we are in a difficult situation .\n",
      "< we re very to the . <EOS>\n",
      "\n",
      "> du bist so ein lugner !\n",
      "= you are such a liar !\n",
      "< you re very very . <EOS>\n",
      "\n",
      "> wir werden im auto warten .\n",
      "= we re going to wait in the car .\n",
      "< we re very very . <EOS>\n",
      "\n",
      "> sie sind au ergewohnlich .\n",
      "= you re extraordinary .\n",
      "< they re very . <EOS>\n",
      "\n",
      "> wir sind untalentiert .\n",
      "= we re untalented .\n",
      "< we re a . <EOS>\n",
      "\n",
      "> sie ist nach wie vor arm .\n",
      "= she is as poor as ever .\n",
      "< she is very very . . <EOS>\n",
      "\n",
      "> ich habe heute nachmittag zeit .\n",
      "= i am free this afternoon .\n",
      "< i am not to the . <EOS>\n",
      "\n",
      "> ich bin mir dessen ziemlich sicher .\n",
      "= i m pretty sure about it .\n",
      "< i am not to the . <EOS>\n",
      "\n",
      "> du bist drei jahre junger als tom .\n",
      "= you re three years younger than tom .\n",
      "< you re very to the . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1, input_lang_german, output_lang_german, pairs_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'not', 'to', 'the', '.', '<EOS>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, _ = evaluate(encoder1, attn_decoder1, ' wasser ', input_lang_german, output_lang_german)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение и загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(encoder1.state_dict(), \"./models/encoder\")\n",
    "torch.save(attn_decoder1.state_dict(), \"./models/decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder2 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "encoder2.load_state_dict(torch.load(\"./models/encoder\"))\n",
    "attn_decoder2.load_state_dict(torch.load(\"./models/decoder\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обученные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_models(encoder_name, decoder_name, input_lang, output_lang, models_path='./models/'):\n",
    "    encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "    decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "    encoder.load_state_dict(torch.load(join(models_path, encoder_name), map_location=lambda storage, loc: storage))\n",
    "    decoder.load_state_dict(torch.load(join(models_path, decoder_name), map_location=lambda storage, loc: storage))\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Немецкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/german_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_german, decoder_german = load_models(\"encoder_german\", \"decoder_german\", input_lang_german, output_lang_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> er erwartet einen anruf .\n",
      "= he is waiting for a telephone call .\n",
      "< he is waiting for a telephone call . <EOS>\n",
      "\n",
      "> jetzt bin ich am flughafen .\n",
      "= i m at the airport now .\n",
      "< i m at the airport now . <EOS>\n",
      "\n",
      "> ich bin fett .\n",
      "= i m fat .\n",
      "< i m fat . <EOS>\n",
      "\n",
      "> ich bin kanadier .\n",
      "= i m canadian .\n",
      "< i m canadian . <EOS>\n",
      "\n",
      "> ich bitte die umstande zu entschuldigen .\n",
      "= i m sorry for the inconvenience .\n",
      "< i m sorry for the inconvenience . <EOS>\n",
      "\n",
      "> ich bin immer punktlich .\n",
      "= i m always on time .\n",
      "< i am always on time . <EOS>\n",
      "\n",
      "> ich bin student .\n",
      "= i m a student .\n",
      "< i m a university student . <EOS>\n",
      "\n",
      "> ich bin sonntags nie zuhause .\n",
      "= i am never at home on sundays .\n",
      "< i am never at home on sundays . <EOS>\n",
      "\n",
      "> ich glaube wohl es hackt !\n",
      "= you re not serious are you ?\n",
      "< you re not going to come . <EOS>\n",
      "\n",
      "> ich bin nicht mehr mude .\n",
      "= i m no longer tired .\n",
      "< i m no longer tired . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder_german, decoder_german, input_lang_german, output_lang_german, pairs_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Испанский"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/spanish_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_spanish, decoder_spanish = load_models(\"encoder_spanish\", \"decoder_spanish\", input_lang_spanish, output_lang_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> estamos todos invitados .\n",
      "= we re all invited .\n",
      "< we re all invited . <EOS>\n",
      "\n",
      "> son conscientes de las dificultades .\n",
      "= they are aware of the difficulties .\n",
      "< they are aware of the difficulties . <EOS>\n",
      "\n",
      "> el se puso senil .\n",
      "= he s gone senile .\n",
      "< he s gone senile . <EOS>\n",
      "\n",
      "> estamos luchando contra el tiempo .\n",
      "= we re fighting against time .\n",
      "< we re wasting against time . <EOS>\n",
      "\n",
      "> estoy agotado .\n",
      "= i m bushed .\n",
      "< i m bushed . <EOS>\n",
      "\n",
      "> no estoy acostumbrado a levantarme temprano .\n",
      "= i m not accustomed to getting up early .\n",
      "< i m not accustomed to getting up early . <EOS>\n",
      "\n",
      "> soy ciega .\n",
      "= i m blind .\n",
      "< i m blind . <EOS>\n",
      "\n",
      "> no me voy a casar nunca .\n",
      "= i m never going to get married .\n",
      "< i m not getting married in getting married . <EOS>\n",
      "\n",
      "> todavia es joven .\n",
      "= he s still young .\n",
      "< she still young young . <EOS>\n",
      "\n",
      "> eres el mas indicado para este trabajo .\n",
      "= you re the best man for the job .\n",
      "< you re the man for the job . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder_spanish, decoder_spanish, input_lang_spanish, output_lang_spanish, pairs_spanish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на внимание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = ich warte hier\n",
      "output = i m waiting for my . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEJCAYAAACJwawLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIo+IqLkk8oiImvv/AdoVGGgktnsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f2a4710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"ich warte hier\", encoder_german, decoder_german, input_lang_german, output_lang_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источники:\n",
    "0. [Теория для этого занятия](https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/Lecture%208%20-%20Conditional%20Language%20Modeling%20with%20Attention.pdf)\n",
    "1. [Pytorch seq2seq tutorial](http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "2. [Про Attention](https://arxiv.org/abs/1406.6247)\n",
    "3. [Еще про Attention](https://arxiv.org/abs/1508.04025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
