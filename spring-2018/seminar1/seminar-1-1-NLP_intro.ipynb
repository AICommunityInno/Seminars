{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–µ–º–∏–Ω–∞—Ä 1. –í–≤–µ–¥–µ–Ω–∏–µ –≤ NLP\n",
    "–ó–∞–¥–∞—á–∞: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤.  \n",
    "–ò–¥–µ—è: –ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ, –∏ –±—É–¥–µ–º –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –ø–æ –Ω–∏–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>is_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://telegram.me/joinchat/AjKh-0GHAsjVpK5Nw...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>–î—Ä–∞–∫–æ–Ω—ã!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  is_female\n",
       "0           0                                                          True\n",
       "1           1                                           –û—Ç–ª–∏—á–Ω–æ!      False\n",
       "2           2  https://telegram.me/joinchat/AjKh-0GHAsjVpK5Nw...      False\n",
       "3           3                                           –î—Ä–∞–∫–æ–Ω—ã!      False\n",
       "4           4                                                         False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./important_conversations.csv').fillna(\"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –≤–µ—â–∏ –∏–∑ —Ç–µ—Ä–≤–µ—Ä–∞\n",
    "$P(A)$ - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è A  \n",
    "$P(A \\cap B)$ - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, —á—Ç–æ A –∏ B   \n",
    "$P(A|B)$ - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è –ê –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏, —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ B\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "–§–æ—Ä–º—É–ª–∞ –ë–∞–π–µ—Å–∞\n",
    "\n",
    "$$P(B|A) = \\frac{P(A | B)P(B)}{P(A)}$$\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä –∑–∞–¥–∞—á–∏:\n",
    "–ü–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ, —É 80% –Ω–æ—Ä–º–æ—Å–Ω—ã—Ö –¥–µ–≤—É—à–µ–∫ –µ—Å—Ç—å –º–æ–ª–æ–¥–æ–π —á–µ–ª–æ–≤–µ–∫. –ü—Ä–∏ —ç—Ç–æ–º, —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –¥–µ–≤—É—à–µ–∫ 60% –Ω–æ—Ä–º–æ—Å–Ω—ã–µ –∏ —É 50% –µ—Å—Ç—å –º–æ–ª–æ–¥–æ–π —á–µ–ª–æ–≤–µ–∫. –í–∞—à –¥—Ä—É–≥ —Å–∫–∞–∑–∞–ª, —á—Ç–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç –≤–∞—Å —Å –æ–¥–∏–Ω–æ–∫–æ–π –¥–µ–≤—É—à–∫–æ–π. –ö–∞–∫–æ–≤–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, —á—Ç–æ –æ–Ω–∞ –±—É–¥–µ—Ç –Ω–æ—Ä–º–æ—Å–Ω–æ–π?\n",
    "\n",
    "#### Naive Bayes\n",
    "$$P(Class = c|Message = d) = \\frac{P(Message = d | Class = c)P(Class = c)}{P(Message = d)}$$\n",
    "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–ª–∞—Å—Å —Å–æ–æ–±—â–µ–Ω–∏—è $d$, –≤—ã–±–∏—Ä–∞–µ–º –∫–ª–∞—Å—Å $c$ —Ç–∞–∫–æ–π, —á—Ç–æ–±—ã $P(Class = c|Message = d)$ –±—ã–ª–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π. \n",
    "$$P(c|d) = \\frac{P(d|c)P(c)}{P(d)} \\propto P(d|c)P(c) \\propto \\prod P(w_i|c)P(c)$$\n",
    "$P(w_i|c)$ - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–≥–æ, —á—Ç–æ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –∏–∑ –∫–ª–∞—Å—Å–∞ $c$ –≤—Å—Ç—Ä–µ—Ç–∏—Ç—Å—è –≤—Å—Ç—Ä–µ—Ç–∏—Ç—Å—è —Å–ª–æ–≤–æ $w_i$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = [item.split() for item in df.text]\n",
    "words_flatten = [w for message in messages for w in message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in words_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–≤', 6205),\n",
       " ('–Ω–µ', 5495),\n",
       " ('–∏', 5182),\n",
       " ('–Ω–∞', 3259),\n",
       " ('—á—Ç–æ', 2970),\n",
       " ('—è', 2888),\n",
       " ('–∞', 2712),\n",
       " ('—ç—Ç–æ', 2384),\n",
       " ('—É', 2162),\n",
       " ('—Å', 2024),\n",
       " ('–∫–∞–∫', 1697),\n",
       " ('—Ç–∞–º', 1390),\n",
       " ('–ø–æ', 1325),\n",
       " ('—Ç—ã', 1305),\n",
       " ('–Ω—É', 1283),\n",
       " ('—Ç–∞–∫', 1224),\n",
       " ('-', 1144),\n",
       " ('–Ω–æ', 1139),\n",
       " ('–æ–Ω', 1019),\n",
       " ('–≤—Å–µ', 1012),\n",
       " ('—Ç–æ', 962),\n",
       " ('–µ—Å—Ç—å', 943),\n",
       " ('–∑–∞', 871),\n",
       " ('–∂–µ', 862),\n",
       " ('–µ—Å–ª–∏', 859),\n",
       " ('–∏–∑', 798),\n",
       " ('–º–µ–Ω—è', 738),\n",
       " ('–≤–æ—Ç', 720),\n",
       " ('–¥–∞', 710),\n",
       " ('–ø—Ä–æ—Å—Ç–æ', 694),\n",
       " ('—É–∂–µ', 690),\n",
       " ('–¥–ª—è', 682),\n",
       " ('–æ–Ω–∏', 676),\n",
       " ('—Ç–æ–ª—å–∫–æ', 669),\n",
       " ('–∫', 653),\n",
       " ('–º–Ω–µ', 642),\n",
       " ('–Ω–µ—Ç', 641),\n",
       " ('–∏–ª–∏', 621),\n",
       " ('–º–æ–∂–Ω–æ', 612),\n",
       " ('–±—ã', 611),\n",
       " ('—Ç—É—Ç', 573),\n",
       " ('–µ—â–µ', 556),\n",
       " ('–ø—Ä–æ', 555),\n",
       " ('–æ—Ç', 546),\n",
       " ('–±—É–¥–µ—Ç', 530),\n",
       " ('—Ç–æ–∂–µ', 530),\n",
       " ('–Ω–∞—Å', 508),\n",
       " ('–Ω–∞–¥–æ', 490),\n",
       " ('–µ–≥–æ', 485),\n",
       " ('–±—ã–ª–æ', 484)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = [item[0] for item in all_words.most_common(500)]\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in zip(messages,df.is_female)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[5000:], featuresets[:5000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9396\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(:)) = True            False : True   =      6.7 : 1.0\n",
      "         contains(—á—Ç–æ–±—ã) = True            False : True   =      6.1 : 1.0\n",
      "        contains(—Ä–µ–±—è—Ç,) = True             True : False  =      5.9 : 1.0\n",
      "             contains(7) = True             True : False  =      5.0 : 1.0\n",
      "             contains(>) = True            False : True   =      4.8 : 1.0\n",
      "          contains(—á—Ç–æ–±) = True            False : True   =      4.7 : 1.0\n",
      "            contains(–µ—ë) = True            False : True   =      4.7 : 1.0\n",
      "        contains(–ø–∏—Ç–µ—Ä–µ) = True             True : False  =      4.6 : 1.0\n",
      "         contains(–∏—Ç–æ–≥–µ) = True             True : False  =      4.6 : 1.0\n",
      "       contains(–∫–ª–∏–º—á–∏–∫) = True             True : False  =      4.6 : 1.0\n",
      "        contains(—Ä–æ—Å—Å–∏–∏) = True             True : False  =      4.4 : 1.0\n",
      "          contains(–æ–ª–µ–≥) = True             True : False  =      4.4 : 1.0\n",
      "          contains(–∞–≥–∞,) = True             True : False  =      4.3 : 1.0\n",
      "             contains(üòÇ) = True             True : False  =      4.3 : 1.0\n",
      "           contains(–∂–µ,) = True            False : True   =      4.2 : 1.0\n",
      "      contains(—Ä–æ–±–æ—Ç–∏–∫—Å) = True             True : False  =      4.2 : 1.0\n",
      "           contains(–µ—â—ë) = True            False : True   =      4.1 : 1.0\n",
      "         contains(–¥–∞–≤–∞–π) = True             True : False  =      4.0 : 1.0\n",
      "           contains(–≤—Å—ë) = True            False : True   =      3.8 : 1.0\n",
      "         contains(–¥–∞–≤–Ω–æ) = True            False : True   =      3.6 : 1.0\n",
      "           contains(—Ç–æ–ø) = True             True : False  =      3.6 : 1.0\n",
      "      contains(–æ—Å–æ–±–µ–Ω–Ω–æ) = True             True : False  =      3.5 : 1.0\n",
      "          contains(–∫–æ–≥–æ) = True             True : False  =      3.4 : 1.0\n",
      "        contains(–¥—Ä—É–≥–æ–π) = True            False : True   =      3.4 : 1.0\n",
      "            contains(:() = True            False : True   =      3.4 : 1.0\n",
      "         contains(–º–æ–≥—É—Ç) = True            False : True   =      3.4 : 1.0\n",
      "             contains(?) = True             True : False  =      3.4 : 1.0\n",
      "          contains(–ø—Ä—è–º) = True             True : False  =      3.4 : 1.0\n",
      "        contains(—Å–∫–∞–∑–∞–ª) = True             True : False  =      3.3 : 1.0\n",
      "         contains(–∫–æ—Å—Ç—è) = True             True : False  =      3.3 : 1.0\n",
      "            contains(in) = True            False : True   =      3.2 : 1.0\n",
      "         contains(–ø–æ–Ω—è–ª) = True            False : True   =      3.2 : 1.0\n",
      "        contains(–æ–¥–Ω–æ–≥–æ) = True            False : True   =      3.2 : 1.0\n",
      "          contains(—ç—Ç–æ?) = True             True : False  =      3.1 : 1.0\n",
      "      contains(–∫–∞–∫–æ–π-—Ç–æ) = True            False : True   =      3.1 : 1.0\n",
      "         contains(–µ—Å—Ç—å,) = True            False : True   =      3.0 : 1.0\n",
      "            contains(–æ–π) = True             True : False  =      3.0 : 1.0\n",
      "        contains(–ø–æ–Ω—è–ª,) = True            False : True   =      3.0 : 1.0\n",
      "         contains(—Ç–æ–≥–æ,) = True            False : True   =      3.0 : 1.0\n",
      "           contains(–∞–≥–∞) = True             True : False  =      2.9 : 1.0\n",
      "        contains(–≤—Ç–æ—Ä–æ–π) = True            False : True   =      2.9 : 1.0\n",
      "           contains(the) = True            False : True   =      2.9 : 1.0\n",
      "        contains(–∫–∞–∑–∞–Ω–∏) = True             True : False  =      2.9 : 1.0\n",
      "        contains(–ø–∏—Å–∞—Ç—å) = True             True : False  =      2.9 : 1.0\n",
      "             contains(4) = True             True : False  =      2.9 : 1.0\n",
      "           contains(–º–æ–≥) = True            False : True   =      2.8 : 1.0\n",
      "           contains(you) = True            False : True   =      2.8 : 1.0\n",
      "         contains(–∏–∑-–∑–∞) = True            False : True   =      2.8 : 1.0\n",
      "         contains(—á–∞—Å—Ç—å) = True            False : True   =      2.8 : 1.0\n",
      "       contains(–≥–æ–≤–æ—Ä–∏—Ç) = True            False : True   =      2.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –°—Ç–µ–º–º–∏–Ω–≥ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è - —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ç–µ—Ä–º—ã (—Å–ª–æ–≤–∞, –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –∏ —Ç.–¥)\n",
    "–°—Ç–µ–º–º–∏–Ω–≥ - –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å–ª–æ–≤ –≤ –Ω–∞—á–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chip'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('chips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'gr': 'PR=', 'lex': '—á–µ—Ä–µ–∑'}], 'text': '—á–µ—Ä–µ–∑'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,–º—É–∂,–Ω–µ–æ–¥=—Ä–æ–¥,–µ–¥', 'lex': '–±–æ—Ç'}], 'text': '–±–æ—Ç–∞'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'SPRO,–µ–¥,1-–ª=(–ø—Ä|–¥–∞—Ç)', 'lex': '—è'}], 'text': '–º–Ω–µ'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'SPRO,–µ–¥,—Å—Ä–µ–¥,–Ω–µ–æ–¥=(–≤–∏–Ω|–∏–º)', 'lex': '—á—Ç–æ-—Ç–æ'}],\n",
       "  'text': '—á—Ç–æ-—Ç–æ'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': '–ø—Ä–æ'}], 'text': '–ø—Ä–æ'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,—Å—Ä–µ–¥,–Ω–µ–æ–¥=(–ø—Ä,–º–Ω|–ø—Ä,–µ–¥|–≤–∏–Ω,–º–Ω|–≤–∏–Ω,–µ–¥|–¥–∞—Ç,–º–Ω|–¥–∞—Ç,–µ–¥|—Ä–æ–¥,–º–Ω|—Ä–æ–¥,–µ–¥|—Ç–≤–æ—Ä,–º–Ω|—Ç–≤–æ—Ä,–µ–¥|–∏–º,–º–Ω|–∏–º,–µ–¥)',\n",
       "    'lex': '–∑–∏–º–±–∞–±–≤–µ'}],\n",
       "  'text': '–ó–∏–º–±–∞–±–≤–µ'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,–ø–µ=–Ω–µ–ø—Ä–æ—à,–µ–¥,–∏–∑—ä—è–≤,3-–ª,–Ω–µ—Å–æ–≤', 'lex': '–≤—ã–¥–∞–≤–∞—Ç—å'}],\n",
       "  'text': '–≤—ã–¥–∞–µ—Ç'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'gr': 'CONJ=', 'lex': '–∞'}], 'text': '–∞'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': '–Ω–∞'}], 'text': '–Ω–∞'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,–º—É–∂,–Ω–µ–æ–¥=–ø—Ä,–µ–¥', 'lex': '—Å–∞–π—Ç'}], 'text': '—Å–∞–π—Ç–µ'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PR=', 'lex': '–ø—Ä–æ'}], 'text': '–ø—Ä–æ'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,–º—É–∂,–Ω–µ–æ–¥=(–≤–∏–Ω,–µ–¥|–∏–º,–µ–¥)', 'lex': '—Å–∏–Ω–¥—Ä–æ–º'}],\n",
       "  'text': '—Å–∏–Ω–¥—Ä–æ–º'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'S,–∏–º—è,–º—É–∂,–æ–¥=(–≤–∏–Ω,–µ–¥|—Ä–æ–¥,–µ–¥)',\n",
       "    'lex': '–∫—É–Ω–∏—Å',\n",
       "    'qual': 'bastard'}],\n",
       "  'text': '–ö—É–Ω–∏—Å–∞'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem.analyze('—á–µ—Ä–µ–∑ –±–æ—Ç–∞ –º–Ω–µ —á—Ç–æ-—Ç–æ –ø—Ä–æ –ó–∏–º–±–∞–±–≤–µ –≤—ã–¥–∞–µ—Ç, –∞ –Ω–∞ —Å–∞–π—Ç–µ –ø—Ä–æ —Å–∏–Ω–¥—Ä–æ–º –ö—É–Ω–∏—Å–∞')\n",
    "#–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏: https://tech.yandex.ru/mystem/doc/grammemes-values-docpage/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°—Ç–æ–ø-—Å–ª–æ–≤–∞ - –Ω–µ–∑–Ω–∞—á–∞—â–∏–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤–Ω–æ—Å–∏—Ç—å –ø–æ–º–µ—Ö–∏ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –æ–±—ã—á–Ω–æ –∏—Ö –ª—É—á—à–µ –≤—ã—Ä–µ–∑–∞—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [item.lower.split() for item in df.text]\n",
    "words_flatten = [w for message in messages for w in message if w not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in words_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9398\n"
     ]
    }
   ],
   "source": [
    "word_features = [item[0] for item in all_words.most_common(500)]\n",
    "featuresets = [(document_features(d), c) for (d,c) in zip(messages,df.is_female)]\n",
    "train_set, test_set = featuresets[5000:], featuresets[:5000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
