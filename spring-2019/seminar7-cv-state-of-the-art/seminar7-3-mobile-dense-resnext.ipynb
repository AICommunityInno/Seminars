{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Community @ Семинар № 7, весна 2019\n",
    "## State-of-the-art в компьютерном зрении. MobileNet, DenseNet, ResNeXt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet [2017, CVPR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ключевые особенности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Эффективная архитектура нейронной сети\n",
    "1. Набор из двух гиперпараметров, которые позволяют построить сеть под конкретные условия (задача, порог точности, железо)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дизайн"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depthwise separable convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Depthwise separable convolution](images/mobile_depthwise_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Объяснение](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d) depthwise separable convolutions на примере"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоимость обычной свертки: $D_K \\cdot D_K \\cdot M \\cdot N \\cdot D_F \\cdot D_F$  \n",
    "Стоимость depthwise separable convolution: $D_K \\cdot D_K \\cdot M \\cdot D_F \\cdot D_F + M \\cdot N \\cdot D_F \\cdot D_F$  \n",
    "Уменьшение стоимости: $\\frac{1}{N} + \\frac{1}{D^2_K}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Архитектура"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Архитектура MobileNet](images/mobile_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Width Multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем уменьшать стоимость вычислений, добавив параметр сжатия сверток $\\alpha \\in (0, 1]$. Тогда сложность вычислений depthwise separable convolution будет $D_K \\cdot D_K \\cdot \\alpha M \\cdot D_F \\cdot D_F + \\alpha M \\cdot \\alpha N \\cdot D_F \\cdot D_F$  \n",
    "При этом сложность уменьшается примерно в $\\alpha^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolution Multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы можем уменьшать размерность входных карт. Для этого используется параметр $\\rho$. Результирующая сложность представлена $D_K \\cdot D_K \\cdot \\alpha M \\cdot \\rho D_F \\cdot \\rho D_F + \\alpha M \\cdot \\alpha N \\cdot \\rho D_F \\cdot \\rho D_F$  \n",
    "Таким образом вычислительная сложность еще падает в $\\rho^2$ раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-1 accuracy on ImageNet: **70.6%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet [2016-2018, CVPE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DenseNet структура](images/dense_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ключевые особенности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выход каждого слоя является входом каждого последующего слоя\n",
    "1. Решают vanishing-gradient проблему\n",
    "1. Усиливают feature propagation и переиспользование признаков\n",
    "1. Уменьшают кол-во параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дизайн"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Архитектура DenseNet](images/dense_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Композитная функция $H_l$: $x_l = H_l([x_0, x_1, ..., x_{l-1}])$\n",
    "1. Конкатенация $[x_0, x_1, ..., x_{l-1}]$ обеспечивается за счет использования Dense блоков, в которых размерности выходных карт одинаковы\n",
    "1. Transition layers - используются между Dense блоками и выполняют функцию уменьшения пространственной и глубинной размерностей\n",
    "1. Коэффициент роста $k$ - указывает кол-во карт признаков, которые добавляются очередным слоем. Итого, слой $l$ имеет $k_0 + k(l-1)$ входных карт признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-1 accuracy on ImageNet: **79.2%**  \n",
    "Top-5 accuracy on ImageNet: **94.7%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшение кол-ва параметров (объема вычислений):\n",
    "201-слойный DenseNet с 20 млн параметров дает такую же точность классификации как 101-слойный ResNet с 40 млн параметров. Поэтому можно считать, что компрессия **в 2 раза**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNeXt [2016-2017, CVPR]  \n",
    "[Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431)  \n",
    "Реализация: [https://github.com/facebookresearch/ResNeXt](https://github.com/facebookresearch/ResNeXt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение блоков ResNet и ResNetX: базовый блок разбивается на Cardinality=32 части, выходы с каждой части суммируются, к результату добавляется вход для формирования residual block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/resnet_resnext_block.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представленный ResNeXt-блок (картинка (a) ниже) сам по себе может быть сведен с помощью тензорных преобразований к блоку (b), формируя топологию, похожую на топологию Inception с той лишь разницей, что базовые блоки здесь представляют одну и ту же функцию.  \n",
    "При этом блок (b) также может быть сведен к блоку (c), который является ни чем иным как групповой сверткой.  \n",
    "Таким образом, ResNeXt-блок - это групповая свертка с residual-членом в виде входа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/resnext_equivalents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущество блока ResNeXt перед Inception блоком**: используется один и тот же базовый блок, что приводит к меньшим усилиям при конфигурации сети.  \n",
    "**Преимущество блока ResNeXt перед ResNet блоком**: сохраняя концепцию residual function и количество параметров в блоке, точность модели целиком становится выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/resnet_vs_resnext.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/resnet_resnext_train_curves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество (при __Cardinality=64__ - количество групп, __d=4__ - количество входных == количество выходных каналов в базовой операции):  \n",
    "Top-1 accuracy on ImageNet: **79.6%**  \n",
    "Top-5 accuracy on ImageNet: **94.7%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
