{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Community @ Семинар № 7, весна 2019\n",
    "## State-of-the-art в компьютерном зрении. ResNet, Inception, Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализации всех этих моделей есть в Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet [2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использует residual модули, из которых строится сеть.  \n",
    "Это позволяет добиться очень большой глубины модели (от 34 до 152 слоев в оригинальной работе), по сравнению с предыдущими архитектурами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/resnet0.png)  \n",
    "![](./images/resnet1.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-152:  \n",
    "Top-1 accuracy: **80.62%**  \n",
    "Top-5 accuracy: **95.51%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-1001 [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027) [2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дизайн"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея - добавление преактивации внутри residual блока."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/resnet2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторы оригинальной статьи тестировали модель на датасете CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-1001:\n",
    "\n",
    "Точность на CIFAR-10:  \n",
    "Top-1 accuracy: **77.3%**  \n",
    "Top-5 accuracy: **95.3%**  \n",
    "\n",
    "Вес модели: **~10.2 Mb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception v3 (GoogLeNet) [2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дизайн"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842)  \n",
    "[Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/pdf/1512.00567)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея - использование Inception-модулей, внутри которых модель считает несколько разных видов сверток для одного и того же слоя сети.  \n",
    "После этого, происходит dstack этих слоев, то есть, их конкатенируют вдоль оси каналов.  \n",
    "Такие модули еще называются multi-branch модулями.  \n",
    "Количество слоев в модели - 22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторы статьи утверждают, что модель работает в 2-3 раза быстрее остальных моделей со схожей точностью, похоже, имея в виду ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница с оригинальным GoogleNet состоит в том, что используются BatchNorm и факторизация сверток: одна большая свертка заменяется несколькими маленькими, что приводит к уменьшению количества параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/inception1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оригинальный Inception слой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/inception_factorization0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замена больших сверток маленькими"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/inception_factorization1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальнейшая факторизация (n = 7 в оригинальной статье)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/inception_factorization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG:  \n",
    "Top-1 accuracy: **75.6%**  \n",
    "\n",
    "Inception v3:  \n",
    "Top-1 accuracy: **81.23%**\n",
    "\n",
    "Вес модели: **96Мб**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception [April 2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дизайн"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/pdf/1610.02357.pdf)  \n",
    "Xception означает extreme inception.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Идеи\n",
    "1. Использовать несколько Separable Convolutions внутри базового residual блока\n",
    "2. Применение 1x1 свертки ко входу X в residual блоке\n",
    "\n",
    "Что происходит? Входные данные разделяются по слоям и к каждому слою независимо применяются свертки. После этого, применяются 1х1 свертки в глубину, то есть, по всем каналам.  \n",
    "Количество параметров в модели почти такое же, как в Inception: ~22M в Inception, ~23M в Xception.  \n",
    "При этом, Xception имеет большую точность, чем Inception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/xception1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Архитектура целиком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/xception2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception V3  \n",
    "Top-1 accuracy: **78.2%**  \n",
    "Top-5 accuracy: **94.1%**  \n",
    "\n",
    "Xception:  \n",
    "Top-1 accuracy: **79.0%**  \n",
    "Top-5 accuracy: **94.5%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
