{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Community @ Семинар № 8, весна 2018\n",
    "## Texture synthesis and Style transfer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как приступать непосредственно к переносу стилей, научимся генерировать текстуры из данного шаблона.   \n",
    "Пусть у нас есть следующий фрагмент\n",
    "<img src='images/pebbles.jpg'>\n",
    "Как мы помним, каждый сверточный слой выделяет на изображении определенные низкоуровневые признаки. Прогоним данное изображение через глубокую сверточную сеть. При этом будем сохранять значения полученные после очередного слоя. Они будут иметь размерность $(N \\times C \\times H \\times W)$. Сейчас будем рассматривать один пример, т.е. размерность будет $(C \\times H \\times W)$.  \n",
    "N - число примеров(в данном случае всегда 1), C - количество карт признаков, H, W - ширина и высота изображения соответсвенно.  \n",
    "<img src='images/featuremap.png'>\n",
    "<div style=\"text-align: right\"><font size=\"2\">Изображение из презентации [2]</font></div>   \n",
    "Данный тензор можно представить в виде $H \\times W$ векторов размерности $C$.\n",
    "\n",
    "Выберем среди них два произвольных вектора $a$ и $b$ и посчитаем для них \n",
    "[матрицу Грама](https://en.wikipedia.org/wiki/Gramian_matrix)\n",
    "    \n",
    "$$G_{ij} = a_{i} * b_{j}$$\n",
    "\n",
    "Она будет приближенно отражать ковариацию между занчениями результатов каждого фильтра. Наша цель - получить изображение в том же распределении. Равенство ковариаций между результатами различных фильтров будет давать искомый эффект.    \n",
    "Почему именно матрица Грама? Потому что, как обычно в глубоком обучении и происходит: попробовали -> заработало. Также, как мы увидим ниже, ее очень просто и эффективно считать.    \n",
    "Теперь посчитаем такие матрицы для всех возможных пар векторов и усредним полученные значения поделив на $H \\times W$. В результате мы получим $(C \\times C)$ матрицу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как считать ее на практике:   \n",
    "Обозначим за $F$ тензор признаков вытянутый в длину так, чтобы в результате размерность стала равна $(C \\times (H * W))$. Тогда   \n",
    "$$G = FF^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним как тренируются нейронные сети. Мы считаем $\\frac{\\delta L}{\\delta w_{ij}^{(k)}}$, а затем вычитаем эти производные из $w_{ij}^{(k)}$. Таким образом мы минимизируем функцию ошибки $L$.  \n",
    "1. Возьмем претренированную сверточную нейронную сеть и зафиксируем ее, т.е. мы больше не собираемся в ней ничего менять. Прогоним оригинальное изображение и посчитаем матрицы Грама $G_{ij}^l$ на каждом слое.    \n",
    "2. Сгенерируем изображение $I$ из случайного шума. Это изображение мы теперь будем улучшать, чтобы оно стало похожим на исходное изображение.\n",
    "3. Прогоним сгенерированное изображение через сеть, так же посчитаем матрицы Грэма $\\hat{G}_{ij}^l$ на каждом слое.   \n",
    "4. Определим функцию ошибки, как взвешенную сумму $L_2^2$ расстояний между матрицами Грама оригинального изображения и соответствующими матрицами сгенерированного изображения.\n",
    "$$E_l = \\sum_{i,j} (G_{ij}^l - \\hat{G}_{ij}^l)^2$$\n",
    "$$L = \\sum_l w_l E_l$$, где $w_l$ - действтельные числа, веса, с которыми ошибка на каждом слое войдет в общую ошибку. Это гиперпараметры, т.е. задаются до тренировки.\n",
    "5. Посчитаем $\\frac{\\delta L}{\\delta I_{ij}}$, где $I_{ij}$ - пиксели изображения $I$. Обновим изображение $I_{ij} = I_{ij} - \\alpha \\frac{\\delta L}{\\delta I_{ij}}$ ($\\alpha$ - learning rate).    \n",
    "6.  Проделаем 3, 4, 5 пока не получим желаемую текстуру. Результат будет хранится в $I$.\n",
    "\n",
    "Все это проиллюстрировано и так же расписано на изображении ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замечания к изображению:\n",
    "1. Здесь формула ошибки изображена только на последнем слое, но лосс считается на нескольких слоях, которые мы сами выбираем. Интуиция следующая: слои в начале сети будут сохранять низкоуровневые признаки, такие как, напрмер, грани, а те, что ближе к концу, будут говорить о структуре изображения в целом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/texture_gen_scheme.png'>\n",
    "<div style=\"text-align: right\"><font size=\"2\">Изображение из статьи [1]</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Восстановление текстуры из разных слоёв извлекает разные признаки оригинального изображения\n",
    "<img src='images/differ_layers.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерировав текстуру изображения можно теперь попытаться наложить эту текстуру другое изображение. Основным изменением является то, что теперь нам необходимо так же ещё считать функцию потерь с тем изображением, от которого мы хотим взять контент.\n",
    "<img src='images/style_stranfer1.jpg'>\n",
    "\n",
    "К функции ошибки, которая считала потери в \"стиле\", добавим часть, которая будут отвечать за оригинал, а именно контент изображения:\n",
    "$$E_{content,k} = w_{content} \\sum_{i,j} (F_{content}^k - F_{gen}^k)^2\\,\\,\\,\\,\\,(1)$$, где $F_{content}^k$ - сохраненная карта признаков оригинального изображения $O$ на слое $k$, $F_{gen}^k$ - карта признаков генерируемого изображения на слое $k$, $w_{content}$ - вес изображения $O$ в финальном лоссе. Тогда:\n",
    "$$L = (\\sum_l w_{style,l} E_{style, l}) + E_{content,k}$$, где $k$ - номер слоя из которого будет извлекаться представление изображения $O$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизируем до тех пор, пока не получим приемлимый результат\n",
    "<img src='images/style_stranfer2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные изменения и улучшения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменяя соотношение весов для контента и стиля в функции потерь можно получать смещение в соответствующую сторону\n",
    "<img src='images/style_stranfer3.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если брать среднее взвешенное матриц Грама нескольких изображений, то можно получать смешение нескольких стилей в один\n",
    "<img src='images/style_stranfer4.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблема:\n",
    "Это всё хорошо, но у нас слишком много проходов по нейронной сети!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение\n",
    "Обучим отдельную сеть, которая выполняет перенос стилей за нас!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Style Transfer\n",
    "1. Тренируем feedforward network для каждого отдельного стиля\n",
    "1. Используем предобученную CNN для подсчёта ошибки\n",
    "1. После обучения получаем стилизованное изображение всего за один прямой проход\n",
    "1. Также используем Instance Normalization вместо Batch Normalization \n",
    "<img src='images/style_stranfer5.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылки:   \n",
    "1. [Статья на arxiv](https://arxiv.org/pdf/1505.07376.pdf)\n",
    "2. [Презентация cs231n](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf)\n",
    "3. [Реализация на ...](https://paperswithcode.com/task/style-transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
