{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Community @ Семинар № 6, весна 2019\n",
    "## Детектирование изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Детектирование изображений** - задача компьютерного зрения, при которой необходимо найти объект определённого класса и показать область на изображении, где этот объект находится"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/2000/1*95lJePt-70PH3PoVfz2yYQ.png)\n",
    "![](https://cdn-images-1.medium.com/max/2000/1*tqbGt2zj-9OP_rjR57r8Zg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regions-Convolutional Neural Networks (R-CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-CNN — 2014\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*REPHY47zAyzgbNKC6zlvBQ.png)\n",
    "1. Отбор кандидатов с помощью [Selective Search](https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf)\n",
    "2. [AlexNet](http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf), но можно использовать и другой экстрактор признаков\n",
    "3. [SVM](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47) для каждого класса\n",
    "4. Линейная регрессия для уточнения рамок\n",
    "\n",
    "\n",
    "#### Selective Search\n",
    "Выбор множества мелких похожих регионов и объединение похожих соседей\n",
    "<img src='images/selective_search.png'>\n",
    "\n",
    "\n",
    "#### Проблемы R-CNN:\n",
    "1. Очень медленная модель, так как нужно для каждого региона делать прямой проход по свёрточной сети (регионов в среднем 2000 на одной картинке)\n",
    "2. Результат алгоритма Selective Search никак не меняется в процессе обучения, из-за чего на вход модели могут поступать регионы плохого качества\n",
    "3. Нужно учить три модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast R-CNN — 2015\n",
    "\n",
    "Основная идея осталось такой же, но теперь вместо подачи областей кандидатов подаётся всё изображение один раз\n",
    "1. Из выхода последнего сверточного слоя определяем регионы, где может быть объект, и превращает их в квадраты используя [RoI-Pool](https://deepsense.ai/region-of-interest-pooling-explained/), чтобы его можно было подавать в полностью связанный слой\n",
    "2. Заменить SVM на слой Softmax\n",
    "3. Заменить линейную регрессию на полносвязный слой\n",
    "\n",
    "<img src='images/fast_rcnn.png'>\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/2000/1*m2QO_wbUPA05mY2q4v7mjg.png)\n",
    "Значительная разница в скорости обучения и прогона между R-CNN и Fast R-CNN\n",
    "\n",
    "Но видно, что ещё осталась проблема: медленный отбор регионов-кандидатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster R-CNN — 2016\n",
    "\n",
    "Раз у нас медленный алгоритм генерации регионов-кандидатов, то можно заменить его сетью, которая на вход принимает выходы со свёрточной сети.\n",
    "\n",
    "<img src='images/faster_rcnn.png'>\n",
    "\n",
    "#### Region proposal framework\n",
    "В RPN по извлечённым CNN признакам скользят свёрткой с окном 3х3. Полученные с её помощью значения передаются в два параллельных полносвязанных слоя: box-regression layer (reg) и box-classification layer (cls).\n",
    "Для того, чтобы разделять признаки, получаемые в CNN, между RPN и модулем детектирования, процесс обучения всей сети построен итерационно, с использованием нескольких шагов:\n",
    "\n",
    "1. Инициализируется и обучается на определение регионов-кандидатов RPN-часть.\n",
    "2. С использованием предлагаемых RPN регионов заново обучается Fast R-CNN часть.\n",
    "3. Обученная сеть детектирования используется, чтобы инициализировать веса для RPN. Общие convolution-слои, однако, фиксируются и производится донастройка только слоёв, специфичных для RPN.\n",
    "4. С зафиксированными convolution-слоями окончательно донастраивается Fast R-CNN.\n",
    "\n",
    "<img src='images/region_proposal.png'>\n",
    "\n",
    "Проблема: хотим не рамки объекта, хотим сам объект!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask R-CNN — 2017\n",
    "\n",
    "Mask R-CNN развивает архитектуру Faster R-CNN путём добавления ещё одной ветки, которая предсказывает положение маски, покрывающей найденный объект, и, таким образом, решает уже задачу instance segmentation\n",
    "\n",
    "<img src='images/mask_rcnn.png'>\n",
    "\n",
    "<img src='images/mask_rcnn_example.png'>\n",
    "\n",
    "Лосс-функция состоиз из суммы ошибок на классификаторе, ошибки определения границы и ошибки маски\n",
    "\n",
    " $$ L = L_{cls} + L_{box} + L_{mask} $$\n",
    "\n",
    "Одна из основных модификаций, возникших из-за необходимости предсказывать маску — изменение процедуры RoIPool(вычисляющей матрицу признаков для региона-кандидата) на так называемую RoIAlign. В RoIPool проблема решалась просто округлением дробных значений до целых. В противоположность этому, в RoIAlign не используется округление, все числа остаются действительными, а для вычисления значений признаков используется билинейная интерполяция по четырём ближайшим целочисленным точкам. \n",
    "\n",
    "![](https://habrastorage.org/webt/ml/27/mq/ml27mqsszmzpo4-j0iv-yobw1os.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Имплементации\n",
    "\n",
    "**Faster R-CNN**\n",
    "\n",
    "PyTorch: https://github.com/longcw/faster_rcnn_pytorch  \n",
    "TensorFlow: https://github.com/smallcorgi/Faster-RCNN_TF  \n",
    "\n",
    "**Mask R-CNN**\n",
    "\n",
    "PyTorch: https://github.com/felixgwu/mask_rcnn_pytorch  \n",
    "TensorFlow: https://github.com/CharlesShang/FastMaskRCNN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ссылки\n",
    "\n",
    "Статья для людей: https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4\n",
    "\n",
    "Статья на русском: https://habr.com/ru/post/421299/\n",
    "\n",
    "Статьи с архива:\n",
    "1. R-CNN: https://arxiv.org/abs/1311.2524\n",
    "1. Fast R-CNN: https://arxiv.org/abs/1504.08083\n",
    "1. Faster R-CNN: https://arxiv.org/abs/1506.01497\n",
    "1. Mask R-CNN: https://arxiv.org/abs/1703.06870"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You Only Look Once (YOLO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv1 — 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея заключается в том, что вместо того, чтобы иметь несколько разных сетей, обучать одну сеть, которая делает всё сразу.\n",
    "![](https://cdn-images-1.medium.com/max/800/1*9nikM2b0u-m67SJpQXftKA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка изображения происходит следующим способом:\n",
    "\n",
    "1. Входное изображение разбивется на сетку S×S (S=7).\n",
    "2. Каждая ячейка сетки предсказывает B ограничивающих рамок (B=2) и оценки уверенности для этих рамок. Оценка уверенности показывает, насколько модель уверена в том, что в рамке есть объект.\n",
    "3. Каждая ограничивающая рамка состоит из 5 предсказаний: x, y, w, h и уверенности. x, y - координаты центра. w, h - ширина и высота рамки.\n",
    "4. Каждая ячейка предсказывает условную вероятность класса объекта для N (N=20) классов.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*YG6heD55fEmZeUKRSlsqlA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Архитектура модели\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1400/1*q5feieizWKYq7dpWjYvCOw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель состоит из 24 сверточных слоев, за которыми следуют 2 полносвязных слоя. Чередующиеся сверточные слои 1×1 уменьшают пространство объектов от предыдущих слоев.\n",
    "\n",
    "Так же существует быстрая версия этой модели с 9 слоями и уменьшенным количеством фильтров в них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция ошибки\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1200/1*1noFJp_rnXsG0TJvtoghFA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda_{noobj}$ - коэффициент, необходимый, чтобы сеть сильно не переобучалась напримерах, когда объекта нет. В оригинальной статье равер 0.5\n",
    "\n",
    "$\\lambda_{coord}$ - коэффициент, необходимый, чтобы сеть лучше выбирала рамки. В оригинальной статье равер 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дополнительные детали\n",
    "\n",
    "1. На всех слоях, за исключением последнего, использовалась leaky ReLU функция активации\n",
    "1. Первые 20 слоёв были предобучены на ImageNet до 88% top-5 accuracy.\n",
    "1. Затем вся сеть обучалась 135 эпох, используя PASCAL VOC 2007 and 2012 в качестве датасета.\n",
    "1. Для того, чтобы исключить множественные перекрывающиеся рамки используется Non-max suppression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение с другими моделями (R-CNN)\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*zxDddLucPHk2sM5DHHEWvw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Немного примеров работы\n",
    "<img src='images/predictions.bmp'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv2 & YOLO9000 — 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конце того же года выходит статья \"YOLO9000: Better, Faster, Stronger\", в которой показаны множественные улучшения первой версии."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Улучшения для YOLOv2 (Better) :\n",
    "\n",
    "1. [Batch Normalization (BN)](https://medium.com/@sh.tsang/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651)\n",
    "1. Классификатор более высокого разрешения. После обучения на изображениях с разрешением 224×224 , YOLOv2 также использует изображения с разрешением 448×448 для тонкой настройки классификатора для 10 эпох на ImageNet\n",
    "1. Предсказание более точного местоположения. Так первая версия не имела ограничений на предсказываемых рамках из-за чего была нестабильна.\n",
    "![](https://cdn-images-1.medium.com/max/900/1*r_LqJNwlbapcFbSc8lytRg.png)\n",
    "1. Изменение размера карты признаков с 7×7 до 13×13 и конкатенирование его с предыдущем слоем размера 26×26×512 изменённого в 13×13×2024\n",
    "1. Обучение на масштабированных изображениях. Размеры изображений - {320, 352, …, 608}\n",
    "    \n",
    "#### Результат\n",
    "![image.png](https://cdn-images-1.medium.com/max/1200/1*2JHsliX3aGSP5QZznsa8pg.png)\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*DWN1vM5yUtqt1gIjTdiUeg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv2 - Darknet-19 (Faster)\n",
    "\n",
    "Помимо всех указанных выше изменений поменялась так же архитектура сети\n",
    "![](https://cdn-images-1.medium.com/max/800/1*iPHGuCWfCOTjrEW187fSZQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение с другими архитектурами, используемыми в YOLOv2\n",
    "![](https://cdn-images-1.medium.com/max/800/1*XNpkCCTVfEDfmGzk5VkL1g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO9000 - WordTree (Stronger) :\n",
    "У нас есть много разных даатесов для класификации и детектирования. Почему бы их не объединить?\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1200/1*1rpDaEiL-4NuTBlk9p0oAg.png)\n",
    "\n",
    "Microsoft COCO: 100 тысяч изображений, 80 классов, лейблы для детектирования, классы в основном имеют обобщённые понятия, такие как “dog” or “boat”.\n",
    "\n",
    "ImageNet: 13 миллионов изображений, 22 тысячи классов, лейблы для классификации, классы обозначают узкие понятия, такие как “Norfolk terrier”, “Yorkshire terrier”, или “Bedlington terrier”\n",
    "\n",
    "При этом классы “dog” и “Norfolk terrier” не взаимоисключающие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому авторы объединили классы в дерево слов (WordTree)\n",
    "![](https://cdn-images-1.medium.com/max/800/1*YiX61mdylOzZYlBFXl9HjA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получилась модель, детектирующая очень специфичные классы\n",
    "<img src='images/prediction_yolo9000.bmp'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv3 — 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спустя некоторое время была опубликована третья версия детектора YOLO с новым экстрактором признаков и ещё несколькими изменениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание классов\n",
    "\n",
    "Вместо Softmax используются независимые логистические классификаторы и binary cross-entropy. Это сделано потому, что могут быть перекрывающиеся метки для классификации нескольких меток, например, если YOLOv3 на более сложном наборе данных, например, Open Images Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание через масштабирование\n",
    "\n",
    "1. Используются три разных масштаба\n",
    "2. Признали извлекаются используя [Feature Pyramid Network](https://towardsdatascience.com/review-fpn-feature-pyramid-network-object-detection-262fc7482610)\n",
    "3. Несколько дополнительных слоёв добавлено в экстрактор признаков Darknet-53.\n",
    "4. Последние три слоя предсказывают параметры ограничивающей рамки, уверенность в том, что в области есть объект и метку класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darknet-53\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*tF1fK8-D5PVDb4khxvIH_g.png)\n",
    "\n",
    "1. Сеть также использует Batch normalization.\n",
    "1. Присутствуют шорткаты, связывающие различные блоки вместе (как в ResNet).\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*U8n4uNBiRzhK8ZYlHbHZpg.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат \n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1080/1*6LvKy1Cb0SQ1PLE26QgBgQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ссылки\n",
    "\n",
    "Статьи с объяснениями и красивыми картинками\n",
    "1. [YOLOv1](https://towardsdatascience.com/yolov1-you-only-look-once-object-detection-e1f3ffec8a89)\n",
    "1. [YOLOv2 & YOLO9000](https://towardsdatascience.com/review-yolov2-yolo9000-you-only-look-once-object-detection-7883d2b02a65)\n",
    "1. [YOLOv3](https://towardsdatascience.com/review-yolov3-you-only-look-once-object-detection-eab75d7a1ba6)\n",
    "\n",
    "Статьи с архива:\n",
    "1. YOLOv1: https://arxiv.org/pdf/1506.02640v5.pdf\n",
    "2. YOLO9000: https://arxiv.org/pdf/1612.08242.pdf\n",
    "3. YOLOv3: https://arxiv.org/pdf/1804.02767.pdf\n",
    "\n",
    "[Список других моделей для детектирования](https://paperswithcode.com/task/object-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
