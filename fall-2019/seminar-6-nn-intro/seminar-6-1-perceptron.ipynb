{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Community @ Семинар № 6\n",
    "## Перцептрон, Нейроны и Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Немного итории\n",
    "\n",
    "1. В 1943 Уоррен Мак-Каллок и Уолтер Питтс на основе работы нервной системы ввели понятие [искусственной нейронной сети](https://ru.wikipedia.org/wiki/%D0%98%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C) и предложили модель [искуственного нейрона](https://ru.wikipedia.org/wiki/%D0%98%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD)\n",
    "1. В начале 1960-х Ф. Розенблат существенно развил и популяризировал идею перцептрона. В то же время появился первый нейрокомпьютер \"Марк-1\", способный распознавать часть букв латинского алфавита.\n",
    "1. В 1969 М. Минский  публикует формальное доказательство ограниченности перцептрона, что приводит к спаду интереса к нейронным сетям.\n",
    "1. В 1974 Пол Дж. Вербос и А. И. Галушкин независимо изобретают [алгоритм обратного распространения ошибки](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B8) для обучения многослойных перцептронов. Но открытие не привлекло особого внимания.\n",
    "1. 1974-1980-е - \"Зима искусственного интеллекта\". \n",
    "1. 1986 - Переоткрыт и существенно развит алгоритм обратного распространения ошибки. Резкое повышение интереса к обучаемым нейронным сетям.\n",
    "1. 2007 - Появляются первые алгоритмы глубокого обучения многослойных нейронных сетей.\n",
    "1. Сейчас - сотни статей связанных с нейронными сетями выходит ежегодно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура перцептрона\n",
    "\n",
    "<img width=\"400\" alt=\"neuron\" src=\"images/neuron.jpg\">\n",
    "\n",
    "Так же его можно представить в виде следующей формулы:\n",
    "\n",
    "$$ f(x, w, b) = \\begin{cases}\n",
    "1, & если \\sum\\limits_{i=1}^{n}{w_i*x_i+b>0} \\\\\n",
    "0, & если \\sum\\limits_{i=1}^{n}{w_i*x_i+b\\le0}\n",
    "\\end{cases}$$\n",
    "\n",
    "Где $w$ - вектор весов, $x$ - вектор входных активаций, $b$ - смещение (bias), а $f(x, w, b)$ - выходная активация перцептрона.\n",
    "Если внести смещение в веса перцептрона и установив в качестве входа на этот вес 1, то формула приобретает более компактный вид\n",
    "\n",
    "$$ f(x, w) = \\begin{cases}\n",
    "1, & w^T \\cdot x > 0 \\\\\n",
    "0, & w^T \\cdot x \\le 0 \n",
    "\\end{cases},$$\n",
    "\n",
    "что можно интерпретировать, как скалярное произведение вектора весов на вектор входов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение проходит следующим образом:\n",
    "1. Для каждого примера из входных данных считаем активацию перцептрона на данном примере.\n",
    "2. Если активация отличается от истинного значения, то обновляем веса, вычитая из них разность истинного и предсказанного значения (почему так, будет объясненно позднее).\n",
    "3. После того, как прошлись по всем примерам, возвращаемся к пункту 1 до тех пор, пока не достингим критерия остановки (определённое количество эпох* или определённый процент ошибок).\n",
    "\n",
    "Эпоха обучения - предъявление всех примеров по одному разу.\n",
    "\n",
    "В итоге после нескольких итераций алгоритм сойдётся к локальному минимуму, линейно разделив классы (не факт, что идеально)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие искусственные нейроны\n",
    "\n",
    "Если обобщать, то перцептрон - это нейрон с функцией активации \n",
    "$$ f(x) = \\begin{cases}\n",
    "1, & x > 0 \\\\\n",
    "0, & x \\le 0 \n",
    "\\end{cases}$$\n",
    "График этой функции:\n",
    "<img width=\"400\" alt=\"perceptron\" src=\"images/perceptron_act.jpg\">\n",
    "\n",
    "При этом существует достаточно большое множество других функций активации, каждая из которых по-своему определяет свойства нейрона. Таких функций существует большое множетсво, но идеальная функция актвации должна обладать следующими свойствами:\n",
    "1. Нелинейность (это позволяет эффективно комбинировать нейроны, нелинейно изменяя пространоство признаков)\n",
    "2. Определена на $\\mathbb{R}$ и дифференцируема на всей области определения.\n",
    "3. Вычислительно проста (чем проще функция, тем быстрее работает сеть, что в некоторых областях является критичным свойстом)\n",
    "\n",
    "\n",
    "Список наиболее известных активационных функций  представлен ниже:\n",
    "1. Линейный нейрон - $f(x) = x$. Самый простой пример активационных функций. \n",
    "1. Сигмоидальный нейрон - $f(x) = \\sigma(x) = \\frac{1}{1+e^{-x}}$. В некотором смысле - это развитие перцептрона, так как возвращает не категоричный ответ 0 или 1, а вещественное число в интервале (0, 1), что можно интерпретировать как уверенность нейрона в том, что пример принадлежит классу 1 или же вероятность, что пример принадлежит к классу 1. Обычно, этот нейрон ставят последним в сети, чтобы получить вероятности класса от модели.\n",
    "<img width=\"400\" alt=\"Sigmoid\" src=\"images/sigmoid.jpg\">\n",
    "\n",
    "3. ReLU (Rectified Linear Unit) - $f(x) = max(0, x)$. Крайне простая функция, и при этом несмотря на кажущуюся линейность, таковой не является, из-за чего активно применяется во многих современных нейросетевых архитектурах. Единственный минус заключается в том, что она недифференцируема в 0.\n",
    "<img width=\"400\" alt=\"ReLU\" src=\"images/relu.jpg\">\n",
    "\n",
    "4. PReLU (Parametrized ReLU) - $f(x) = \\max\\left(0,x\\right)+a\\min\\left(0,\\ x\\right)$. Модификация ReLU, в которой добавляется обучаемый параметр $a$, отвечающий за наклон прямой при отрицательном значении аргумента. Предоставляет большую гибкость, не сильно увеличивая при этом вычислительную сложность. Имеет тот же недостаток с недифференцируемостью в 0, что и ReLU.\n",
    "<img width=\"400\" alt=\"PReLU\" src=\"images/prelu.jpg\">\n",
    "\n",
    "5. Softplus - $f\\left(x\\right)=\\ln\\left(1+e^{x}\\right)$. \"Гладкая\" модификация  ReLU. Дифференцируема на всей области определения.\n",
    "<img width=\"400\" alt=\"Softplus\" src=\"images/softplus.jpg\">\n",
    "\n",
    "6. Swish - $f\\left(x\\right)=x\\sigma(x)$. Ещё одна гладкая модификация ReLU. В [статье](https://arxiv.org/pdf/1710.05941.pdf) показано, что для многих задач она даёт прирост по точности в сравнении с другими активациями. Но на практике для конкретной задачи лучше явно сравнивать эффективность.\n",
    "<img width=\"400\" alt=\"Swish\" src=\"images/swish.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "Для того, чтобы обучать нейроны используется алгоритм градиентного спуска. Кратко его можно описать следующим образом:\n",
    "$$\n",
    "W=W-a\\cdot\\frac{dL}{dW}\n",
    "$$\n",
    "где $W$ - тензор обучаемых параметров (Тензор - обобщение понятий вектор и матрица), $L$ - функция потерь нашей модели зависящая от параметров модели и данных, $\\frac{dL}{dW}$ - градиент функции потерь по всем обучаемым параметрам, $a$ - параметр, определяющий скорость обучения (learning rate).\n",
    "\n",
    "Идея заключается в том, что мы хотим найти такие параметры $W$, при которых значение функции ошибки $L$ будет минимальным. Градиент же в свою очередь показывает направление максимального роста функции. Поэтому, если если мы возьмём значение градиента с минусом, то получим направление направление максимального спада функции. Двигаясь в этом направлении, изменяя параметры, мы будем приближаться к минимуму функции, что нам и требуется.\n",
    "\n",
    "<img alt=\"Карта поверхности функции ошибки\" src=\"images/surface.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим работу алгоритма градиентного спуска на примере сигмоидального нейрона. В качестве функции потерь возьмём MSE - сумму квадратов разности (обычно, для сигмоидального нейрона используют [перекрёстную-ентропию](https://ru.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D0%B5%D0%BA%D1%80%D1%91%D1%81%D1%82%D0%BD%D0%B0%D1%8F_%D1%8D%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%8F), но для простоты используем MSE, для других функций потерь алгоритм аналогичный)\n",
    "$$MSE=\\frac{1}{2n}\\sum_{i=0}^n {(y_i - \\hat{y_i})^2} = \\frac{1}{2n}\\left \\|y - \\hat{y}  \\right \\|_2^2$$\n",
    "где $n$ - количество примеров в обучающей выборке, $y$ - вектор истинных значений, $\\hat{y}$ - вектор предсказанных значений. В случае сигмоидального перцептрона $\\hat{y} = \\sigma(X \\cdot w)$, $w$ - вектор параметров размера $(m, 1)$, $X$ - матрица примеров размера $(n, m)$.\n",
    "\n",
    "Расписав $\\hat{y}$ в нашей функции потерь, получаем\n",
    "$$\n",
    "L(X, w) = MSE(X, w) = \\frac{1}{2n}\\left \\|y - \\sigma(X \\cdot w)  \\right \\|_2^2\n",
    "$$\n",
    "Теперь осталось всего лишь найти градиент \\frac{dL}{dw} по параметрам и дело сделано.\n",
    "Тут понядобятся правило цепи для дифференцирование сложной функции и понимание того, как брать производную по тензору.\n",
    "С первым всё просто: $\\frac{df}{dx}=\\frac{df}{dy}\\frac{dy}{dx}$ в нотации Лейбница или $f\\left(g\\left(x\\right)\\right)'=f'\\left(g\\left(x\\right)\\right)\\cdot g\\left(x\\right)'$ в нотации Ньютона. Чтобы не тратить время скажу сразу, что $\\sigma(x) = (1-\\sigma(x))\\sigma(x)$ (кому интересно, можете попрактиковаться, доказав это).\n",
    "Со вторым дела обстоят несколько сложнее, но в этом тоже легко разобраться. Рассмотрим $\\hat{y}$ как вектор-столбец.\n",
    "\n",
    "$$ \\hat {y}=\\begin{bmatrix}\n",
    "\\hat {y}_1\\\\\n",
    "\\hat {y}_2\\\\ \n",
    "...\\\\ \n",
    "\\hat y_{n-1}\\\\ \n",
    "\\hat y_{n}\\\\ \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\sigma(X_1 \\cdot w)\\\\\n",
    "\\sigma(X_2 \\cdot w)\\\\ \n",
    "...\\\\ \n",
    "\\sigma(X_{n-1} \\cdot w)\\\\ \n",
    "\\sigma(X_n \\cdot w)\\\\ \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "где $X_i$ - это i-тая строка в $X$ или же i-тый пример из данных.\n",
    "\n",
    "Если мы хотим взять производную от этого вектора по одному параметру весов $w_i$, то нам нужно от каждого элемента этого вектора взять производную по этому параметру:\n",
    "$$\n",
    "\\frac{d \\hat y}{d w_i}\n",
    "=\\begin{bmatrix}\n",
    "\\frac{\\delta \\hat y_1}{\\delta w_i}\\\\\n",
    "\\frac{\\delta \\hat y_2}{\\delta w_i}\\\\ \n",
    "...\\\\ \n",
    "\\frac{\\delta \\hat y_{n-1}}{\\delta w_i}\\\\ \n",
    "\\frac{\\delta \\hat y_n}{\\delta w_i}\\\\ \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\delta \\sigma(X_1 \\cdot w)}{\\delta w_i}\\\\\n",
    "\\frac{\\delta \\sigma(X_2 \\cdot w)}{\\delta w_i}\\\\ \n",
    "...\\\\ \n",
    "\\frac{\\delta \\sigma(X_{n-1} \\cdot w)}{\\delta w_i}\\\\ \n",
    "\\frac{\\delta \\sigma(X_n \\cdot w)}{\\delta w_i}\\\\ \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "(1-\\sigma(X_1 \\cdot w))\\sigma(X_1 \\cdot w)\\frac{\\delta X_1 \\cdot w}{\\delta w_i}\\\\\n",
    "(1-\\sigma(X_2 \\cdot w))\\sigma(X_2 \\cdot w)\\frac{\\delta X_2 \\cdot w}{\\delta w_i}\\\\ \n",
    "...\\\\ \n",
    "(1-\\sigma(X_{n-1} \\cdot w))\\sigma(X_{n-1} \\cdot w)\\frac{\\delta X_{n-1} \\cdot w}{\\delta w_i}\\\\ \n",
    "(1-\\sigma(X_n \\cdot w))\\sigma(X_n \\cdot w)\\frac{\\delta X_n \\cdot w}{\\delta w_i}\\\\ \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "(1-\\sigma(X_1 \\cdot w))\\sigma(X_1 \\cdot w)X_{1,i}\\\\\n",
    "(1-\\sigma(X_2 \\cdot w))\\sigma(X_2 \\cdot w)X_{2,i}\\\\ \n",
    "...\\\\ \n",
    "(1-\\sigma(X_{n-1} \\cdot w))\\sigma(X_{n-1} \\cdot w)X_{n-1,i}\\\\ \n",
    "(1-\\sigma(X_n \\cdot w))\\sigma(X_n \\cdot w)X_{n,i}\\\\ \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "В итоге получившийся вектор можно компактно записать как\n",
    "$$\n",
    "\\frac{\\delta \\hat y}{\\delta w_i}=(1 - \\sigma(X \\cdot w)) \\circ  \\sigma(X \\cdot w) \\circ X_{,i}\n",
    "$$\n",
    "где $X_{,i}$ - i-тый столбец матрицы $X$, $\\circ$ - поэлементное умножение векторов.\n",
    "Но что, если от числа взять производную по вектору? Ситуация аналогичная, только у нас получится вектор, в которым i-тый элемент будет производной числа по i-тому элементу.\n",
    "Допустим, у нас есть некоторая функция f(x), которая принимает на вход вектор x, а возвращает число. Примером такой функции может быть квадрат нормы вектора $f(x) = \\left \\|x  \\right \\|_2^2$. Соответственно, производной  $f(x)$ по $x$ будет\n",
    "$$\n",
    "\\frac{df\\left(x\\right)}{dx}=\\frac{d \\left \\|x  \\right \\|_2^2}{dx}=\n",
    "\\begin{bmatrix}\n",
    "\\frac{d \\left \\|x  \\right \\|_2^2}{dx_1} &\n",
    "\\frac{d \\left \\|x  \\right \\|_2^2}{dx_2} & \n",
    "... &\n",
    "\\frac{d \\left \\|x  \\right \\|_2^2}{dx_{n-1}} &\n",
    "\\frac{d \\left \\|x  \\right \\|_2^2}{dx_n}\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\frac{d x_1^2}{dx_1} &\n",
    "\\frac{d x_2^2}{dx_2} & \n",
    "... &\n",
    "\\frac{d x_{n-1}^2}{dx_{n-1}} & \n",
    "\\frac{d x_n^2}{dx_n} & \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "2x_1 &\n",
    "2x_2 &\n",
    "... & \n",
    "2x_{n-1} & \n",
    "2x_n & \n",
    "\\end{bmatrix}=2x^T\n",
    "$$\n",
    "\n",
    "Заметьте, что в данном случае получается вектор-строка, а не вектор-столбец."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы также можем взять производную от вектора по вектору. Допустим мы хотим взять производную от вектора $y$ по вектору $x$. После подобной операции у нас получится матрица $Z$, где $Z_{i,j}= \\frac{dy_i}{dx_j}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь, используя эти правила, мы можем взять производную от функции потерь по вектору параметров.\n",
    "$$\n",
    "\\frac{dL}{dw}=\\frac{1}{2n} \\frac{d(\\left \\|y - \\sigma(X \\cdot w)  \\right \\|_2^2)}{dw}=\n",
    "\\frac{1}{n}(y - \\sigma(X \\cdot w))^T \\frac{d(y - \\sigma(X \\cdot w))}{dw}=\n",
    "\\frac{1}{n}(\\sigma(X \\cdot w)-y)^T \\frac{d\\sigma(X \\cdot w)}{dw}\n",
    "$$\n",
    "\n",
    "Эта производная на первый взгляд не кажется сложной, но на второй взгляд может повергнуть в смятение и только лишь на третий становится понятно, что не всё так страшно. Выше мы уже находили производную от $\\frac{\\delta \\hat y}{\\delta w_i}$. В нашем случае принципиально ничего не поменялось, если представить производную $\\frac{\\delta \\hat y}{\\delta w_i}$ как число, то производную $\\frac{\\delta \\hat y}{\\delta w}$ можно рассматривать как вектор.\n",
    "\n",
    "$$\n",
    "\\frac{\\delta \\hat y}{\\delta w}=\n",
    "\\begin{bmatrix}\n",
    "(1 - \\sigma(X \\cdot w)) \\circ  \\sigma(X \\cdot w) \\circ X_{,1} \\\\\n",
    "(1 - \\sigma(X \\cdot w)) \\circ  \\sigma(X \\cdot w) \\circ X_{,2} \\\\\n",
    "... \\\\ \n",
    "(1 - \\sigma(X \\cdot w)) \\circ  \\sigma(X \\cdot w) \\circ X_{,m-1} \\\\ \n",
    "(1 - \\sigma(X \\cdot w)) \\circ  \\sigma(X \\cdot w) \\circ X_{,m} \\\\ \n",
    "\\end{bmatrix}^T=\n",
    "((1 - \\sigma(X \\cdot w)) \\circ  \\sigma(X \\cdot w))^T \\circ\n",
    "\\begin{bmatrix}\n",
    "X_{,1} \\\\\n",
    "X_{,2} \\\\\n",
    "... \\\\ \n",
    "X_{,m-1} \\\\ \n",
    "X_{,m} \\\\ \n",
    "\\end{bmatrix}^T=\n",
    "((1 - \\sigma(X \\cdot w)) \\circ  \\sigma(X \\cdot w))^T \\circ X\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После подстановки полученной производной имеем следующую формулу производной от функции потерь по параметрам.\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dw} = \\frac{1}{n}((\\sigma(X \\cdot w)-y) \\circ (1 - \\sigma(X \\cdot w)) \\circ  \\sigma(X \\cdot w))^T \\cdot X\n",
    "$$\n",
    "\n",
    "Посчитав и сохранив значение $A = \\sigma(X \\cdot w) $ можно заметно сократить количество вычислений.\n",
    "\n",
    "Если посмотреть на размерности $((A-y) \\circ (1 - A) \\circ A)^T$ - $(1, n)$ и $X$ - $(n, m)$, то можно заметить, что при большом количестве параметров может быть затратно по памяти считать производную сразу по всем примерам. Поэтому на практике чаще используют стохастический градиентный спуск, в котором, на обучение модели подают относительно небольшую выборку, называемую батчем. При этом примеры для выборки выбираются случайно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источники:  \n",
    "\n",
    "[1] Материал адаптирован из курса https://stepik.org/course/401/syllabus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
