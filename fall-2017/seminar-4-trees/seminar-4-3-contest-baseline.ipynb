{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os.path import exists, join\n",
    "from os import makedirs\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В прошлый раз мы использовали метрику `Accuracy`. В этот раз мы будем использовать `F1-score`.  \n",
    "Посмотрим, что это такое:   \n",
    "[Источник](https://habrahabr.ru/company/ods/blog/328372/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/precision_recall.jpg\" alt=\"Drawing\" style=\"height: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`Precision`** - точность (не путайте с `Accuracy`), эта метрика говорит нам долю объектов, которые классификатор назвал положительными (1) и при этом они действительно положительные.  \n",
    "    То есть, `precision` - способность классификатора отличать положительные примеры от отрицательных (0).  \n",
    "    \n",
    "    \n",
    "* **`Recall`** - полнота, эта метрика говорит нам, какую долю примеров положительного класса классификатор нашел из всех примеров положительного класса.  \n",
    "    То есть, `recall` - способность классификатора в принципе обнаруживать положительный класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти две метрики можно объединить в одну - F1-score:  \n",
    "$$F1 = \\frac{2\\cdot\\textit{Pr}\\cdot\\textit{Rc}}{\\textit{Pr} + \\textit{Rc}},$$ где $\\textit{Pr}$ - **Precision**, $\\textit{Rc}$ - **Recall**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсказка для чтения данных: `pd.merge()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train/train3.csv')\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "y_train = train_data['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь используем кросс-валидацию. [Подробнее](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88259109  0.96267696  0.83888889  0.85784314  0.92368421  0.86057692\n",
      "  0.91812865  0.96190476  1.          1.        ]\n",
      "F1 score: 0.92 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=10, scoring='f1_macro')\n",
    "print(scores)\n",
    "print(\"F1 score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test/test4.csv')\n",
    "x_test = test_data[test_data.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir = 'results/'\n",
    "if not exists(results_dir):\n",
    "    makedirs(results_dir)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    'Category': y_test\n",
    "}).to_csv(join(results_dir, 'submission.csv'), index=False, columns=['ID', 'Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные взяты из открытого источника.  \n",
    "**Авторы**: Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
