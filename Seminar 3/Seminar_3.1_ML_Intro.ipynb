{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # AI Community @ Семинар  № 3\n",
    " ## Введение в машинное обучение\n",
    "Суть: Мы знаем какую-то характеристику объектов, надо научиться узнавать эту же характеристику для похожих объектов  \n",
    " ### Строгая формулировка\n",
    " Дано: множество объектов $O$   \n",
    " Каждый объект имеет множество определяющих переменных (known characteristics) $x \\in X$ и определяемых переменных (predicted characteristics) $y \\in Y$\n",
    " \n",
    " $o \\in O \\to (x,y)$\n",
    " \n",
    " Задача: найти функцию, наиболее точно приближающую $X \\to Y$\n",
    " \n",
    " Классификация - если $Y$ конечно  \n",
    " Регрессия - если $Y = \\mathbb{R} $ \n",
    " \n",
    " ### Supervised и unsupervised learning\n",
    " Supervised - есть какой-то набор данных, для которого известны и $x$, и $y$  \n",
    " Unsupervised - $y$ неизвестно для всех данных\n",
    " \n",
    " #### Примеры:\n",
    " Superised:\n",
    " <img src=\"./data/Regression_Analysis_Linear.gif\" alt=\"Drawing\" style=\"height: 400px;\"/>\n",
    " \n",
    " Unsupervised\n",
    " ![Clustering](./data/xclara-clusters-colour.png)\n",
    " \n",
    " ### Стандартная процедура для supervised learning\n",
    " 1. Разбить выборку на train и test\n",
    " 2. Выбрать метод\n",
    " 3. Обучить его на train\n",
    " 4. Посмотреть, что он предсказывает для test\n",
    " 5. Сравнить с истинными значениями для test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаблон алгоритма:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    train_x, test_x, train_y, test_y = extract(data)\n",
    "    predictor = MySuperPredictor()\n",
    "    predictor.fit(train_x, train_y)\n",
    "    preds = predictor.predict(test_x)\n",
    "    score = compare(preds, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Case study\n",
    " Распознавание рукописных цифр\n",
    " \n",
    " http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_digit(digit):\n",
    "    \"\"\"\n",
    "    Displays sample from MNIST in human-readable format\n",
    "    \n",
    "    Arguments:\n",
    "    digit - numpy 1-d array of size 64\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=(7, 1))\n",
    "    ax = f.add_subplot(111)\n",
    "    ax.matshow(digit.reshape(8, 8))\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print('x =', digits.data[i])\n",
    "    print('y =', digits.target[ i])\n",
    "    show_digit(digits.data[i])\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение выборки на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2)\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Линейная регрессия\n",
    "  <img src=\"./data/Regression_Analysis_Linear.gif\" alt=\"Drawing\" style=\"height: 300px;\"/>\n",
    "  Данные аппроксимируются линией таким образом, чтобы среднее расстояние от точки до линии было наименьшим.  \n",
    "  Почитать ещё: https://habrahabr.ru/company/ods/blog/323890/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "predictor = LinearRegression()\n",
    "predictor.fit(X_train, y_train)\n",
    "y_pred = predictor.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем, насколько хороши предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = np.round(y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим пример, где предсказано правильно, и где неправильно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sample = X_test[y_test == y_pred][0]\n",
    "print('true:', y_test[y_test == y_pred][0])\n",
    "print('predicted:', y_pred[y_test == y_pred][0])\n",
    "show_digit(true_sample)\n",
    "\n",
    "false_sample = X_test[y_test != y_pred][0]\n",
    "print('true:', y_test[y_test != y_pred][0])\n",
    "print('predicted:', y_pred[y_test != y_pred][0])\n",
    "show_digit(false_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Логистическая регрессия\n",
    "  <img src=\"./data/LogReg.png\" alt=\"Drawing\" style=\"height: 300px;\"/>\n",
    "  То же самое, что и линейная регрессия, но аппроксимация ведётся не линией $y = \\theta_0 + \\theta_1x_1 + ... + \\theta_nx_n$, а функцией $$y = \\frac{1}{1+e^{-z}}$$ Где $z = \\theta_0 + \\theta_1x_1 + ... + \\theta_nx_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "predictor = LogisticRegression()\n",
    "predictor.fit(X_train, y_train)\n",
    "y_pred = predictor.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sample = X_test[y_test == y_pred][0]\n",
    "print('true:', y_test[y_test == y_pred][0])\n",
    "print('predicted:', y_pred[y_test == y_pred][0])\n",
    "show_digit(true_sample)\n",
    "\n",
    "false_sample = X_test[y_test != y_pred][0]\n",
    "print('true:', y_test[y_test != y_pred][0])\n",
    "print('predicted:', y_pred[y_test != y_pred][0])\n",
    "show_digit(false_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### k-nearest-neighbors classifier\n",
    " <img src=\"./data/knn_classifier.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    " Для заданной точки алгоритм ищет k ближайших к ней соседей из обучающей выборки, и возвращает класс, который встречался среди этих k точек чаще остальных.  \n",
    " Почитать ещё: https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "predictor = KNeighborsClassifier(n_neighbors=4)\n",
    "predictor.fit(X_train, y_train)\n",
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_sample = X_test[y_test == y_pred][0]\n",
    "print('true:', y_test[y_test == y_pred][0])\n",
    "print('predicted:', y_pred[y_test == y_pred][0])\n",
    "show_digit(true_sample)\n",
    "\n",
    "false_sample = X_test[y_test != y_pred][0]\n",
    "print('true:', y_test[y_test != y_pred][0])\n",
    "print('predicted:', y_pred[y_test != y_pred][0])\n",
    "show_digit(false_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Нейронная сеть\n",
    "  ![LR](./data/220px-Neural_network.svg.png)\n",
    "  Несколько линейных регрессий, объединённых в сеть.  \n",
    "  Почитать ещё: https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "predictor = MLPClassifier()\n",
    "predictor.fit(X_train, y_train)\n",
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_sample = X_test[y_test == y_pred][0]\n",
    "print('true:', y_test[y_test == y_pred][0])\n",
    "print('predicted:', y_pred[y_test == y_pred][0])\n",
    "show_digit(true_sample)\n",
    "\n",
    "false_sample = X_test[y_test != y_pred][0]\n",
    "print('true:', y_test[y_test != y_pred][0])\n",
    "print('predicted:', y_pred[y_test != y_pred][0])\n",
    "show_digit(false_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деревья\n",
    "<img src=\"./data/F3.large.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "С помощью статистических методов строится дерево решений (или несколько деревьев). Каждый раз при предсказывании алгоритм проходит дерево от корня до одного из листов и возвращает класс, соответствующий листу.  \n",
    "Почитать ещё: https://sadanand-singh.github.io/posts/treebasedmodels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "predictor = GradientBoostingClassifier(n_estimators=5)\n",
    "predictor.fit(X_train, y_train)\n",
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_sample = X_test[y_test == y_pred][0]\n",
    "print('true:', y_test[y_test == y_pred][0])\n",
    "print('predicted:', y_pred[y_test == y_pred][0])\n",
    "show_digit(true_sample)\n",
    "\n",
    "false_sample = X_test[y_test != y_pred][0]\n",
    "print('true:', y_test[y_test != y_pred][0])\n",
    "print('predicted:', y_pred[y_test != y_pred][0])\n",
    "show_digit(false_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация (KMeans)\n",
    "  <img src=\"./data/kmeans.png\" alt=\"Drawing\" style=\"height: 300px;\"/>\n",
    " Алгоритм ищет K центров кластеров и относит каждую точку к тому кластеру, которому соответствует ближайший из центров.  \n",
    " При этом центры выбираются таким образом, чтобы сумма расстояний от точки до центра соответствующего ей кластера была минимальной\n",
    " Почитать ещё: https://www.datascience.com/blog/introduction-to-k-means-clustering-algorithm-learn-data-science-tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusterer = KMeans(n_clusters=10)\n",
    "classes = clusterer.fit_predict(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in np.unique(classes):\n",
    "    f, axs = plt.subplots(1, 5, sharey=True, figsize=(7, 1))\n",
    "    for i,sample in enumerate(digits.data[classes == i][:5]):\n",
    "        axs[i].matshow(sample.reshape((8, 8)))\n",
    "        axs[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисуем центры кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for center in clusterer.cluster_centers_:\n",
    "    f = plt.figure(figsize=(7, 1))\n",
    "    ax = f.add_subplot(111)\n",
    "    ax.matshow(center.reshape(8, 8))\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
